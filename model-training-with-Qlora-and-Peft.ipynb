{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:57:15.531244Z","iopub.execute_input":"2023-12-09T16:57:15.531504Z","iopub.status.idle":"2023-12-09T16:57:16.949413Z","shell.execute_reply.started":"2023-12-09T16:57:15.531479Z","shell.execute_reply":"2023-12-09T16:57:16.948098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install  -U trl  git+https://github.com/huggingface/peft.git\n!pip install  datasets \n!pip install bitsandbytes \n!pip install einops \n!pip install wandb \n!pip install transformers \n!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:57:16.951827Z","iopub.execute_input":"2023-12-09T16:57:16.952545Z","iopub.status.idle":"2023-12-09T16:59:00.634215Z","shell.execute_reply.started":"2023-12-09T16:57:16.952510Z","shell.execute_reply":"2023-12-09T16:59:00.633016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport getpass\n\n#os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = getpass.getpass(\"API_Token:\")\nassert os.environ[\"HUGGING_FACE_HUB_TOKEN\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:59:00.635893Z","iopub.execute_input":"2023-12-09T16:59:00.636275Z","iopub.status.idle":"2023-12-09T16:59:00.641477Z","shell.execute_reply.started":"2023-12-09T16:59:00.636241Z","shell.execute_reply":"2023-12-09T16:59:00.640524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $HUGGING_FACE_HUB_TOKEN","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:59:00.643681Z","iopub.execute_input":"2023-12-09T16:59:00.644056Z","iopub.status.idle":"2023-12-09T16:59:02.204714Z","shell.execute_reply.started":"2023-12-09T16:59:00.644032Z","shell.execute_reply":"2023-12-09T16:59:02.203787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset_name = 'Ekkologico/phyton-clean-tiny-codes' \ndataset = load_dataset(dataset_name, split=\"train\", use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:59:02.206086Z","iopub.execute_input":"2023-12-09T16:59:02.206378Z","iopub.status.idle":"2023-12-09T16:59:08.297790Z","shell.execute_reply.started":"2023-12-09T16:59:02.206352Z","shell.execute_reply":"2023-12-09T16:59:08.296876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport os\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n\n\n\nmodel_name = \"meta-llama/Llama-2-13b-chat-hf\"\nMAX_NEW_TOKENS = 128\n\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)\n\ndevice_map = \"auto\"\nmax_memory = {0: \"13GiB\", 1: \"13GiB\", \"cpu\": \"28GiB\"}\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    load_in_4bit=True,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    device_map = device_map,\n    max_memory = max_memory\n)\nmodel.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:59:08.299034Z","iopub.execute_input":"2023-12-09T16:59:08.299493Z","iopub.status.idle":"2023-12-09T17:03:22.433253Z","shell.execute_reply.started":"2023-12-09T16:59:08.299466Z","shell.execute_reply":"2023-12-09T17:03:22.432319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2023-12-09T17:03:22.434598Z","iopub.execute_input":"2023-12-09T17:03:22.434964Z","iopub.status.idle":"2023-12-09T17:03:22.443157Z","shell.execute_reply.started":"2023-12-09T17:03:22.434936Z","shell.execute_reply":"2023-12-09T17:03:22.442281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-09T17:03:22.444344Z","iopub.execute_input":"2023-12-09T17:03:22.444617Z","iopub.status.idle":"2023-12-09T17:03:23.878552Z","shell.execute_reply.started":"2023-12-09T17:03:22.444593Z","shell.execute_reply":"2023-12-09T17:03:23.877536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nlora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\n\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T17:03:23.879874Z","iopub.execute_input":"2023-12-09T17:03:23.880261Z","iopub.status.idle":"2023-12-09T17:03:23.936687Z","shell.execute_reply.started":"2023-12-09T17:03:23.880227Z","shell.execute_reply":"2023-12-09T17:03:23.935952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\noutput_dir = \"./results\"\nper_device_train_batch_size = 4\ngradient_accumulation_steps = 4\noptim = \"paged_adamw_32bit\"\nsave_steps = 100\nlogging_steps = 10\nlearning_rate = 2e-4\nmax_grad_norm = 0.3\nmax_steps = 100\nwarmup_ratio = 0.03\nlr_scheduler_type = \"constant\"\neval_accumulation_steps=1\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n    eval_accumulation_steps=eval_accumulation_steps,\n    gradient_checkpointing=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T17:03:23.939363Z","iopub.execute_input":"2023-12-09T17:03:23.939642Z","iopub.status.idle":"2023-12-09T17:03:23.949366Z","shell.execute_reply.started":"2023-12-09T17:03:23.939618Z","shell.execute_reply":"2023-12-09T17:03:23.948617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\nmax_seq_length = 512\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"combined\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T17:03:23.950526Z","iopub.execute_input":"2023-12-09T17:03:23.951071Z","iopub.status.idle":"2023-12-09T17:05:06.777567Z","shell.execute_reply.started":"2023-12-09T17:03:23.951038Z","shell.execute_reply":"2023-12-09T17:05:06.776756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, module in trainer.model.named_modules():\n    if \"norm\" in name:\n        module = module.to(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T17:05:06.778692Z","iopub.execute_input":"2023-12-09T17:05:06.779040Z","iopub.status.idle":"2023-12-09T17:05:06.790834Z","shell.execute_reply.started":"2023-12-09T17:05:06.779014Z","shell.execute_reply":"2023-12-09T17:05:06.789925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T17:05:06.792011Z","iopub.execute_input":"2023-12-09T17:05:06.792289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\nmodel_to_save.save_pretrained(\"outputs\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: Create a Python function that takes in a string and a list of words and returns true if the string contains all the words in the list. ### Input: 'This is a test', ['test', 'this', 'is']\"\ndevice = \"cuda:0\"\n\ninputs = tokenizer(text, return_tensors=\"pt\").to(device)\noutputs = model.generate(**inputs, max_new_tokens=128)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"api.upload_folder(\n    folder_path=\"./outputs\",\n    path_in_repo = \".\",\n    repo_id=\"Ekkologico/Llama-2-13b-chat-python_code_instructions_nampdn-ai_tiny-codes\",\n    repo_type=\"model\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}